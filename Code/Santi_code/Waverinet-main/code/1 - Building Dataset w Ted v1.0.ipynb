{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building final Dataset using Ted Talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this Notebook is to prepare the dataset that is going to be used by a model or to modify an existing one by changing the noise or incompletion percentage.\n",
    "\n",
    "The data has been found in a Mozilla forum with semi-open datasets focused in audio files. Here is the main source: https://voice.mozilla.org/en/datasets.\n",
    "\n",
    "![title](img/mozilla.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can found the Ted Talks TEDLIUM v3.0. (License: CC-BY-NC-ND 3.0)\n",
    "\n",
    "Once downloaded, lets see how the files are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studying of the original Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded folder has 221 GB of audio files as you can see:\n",
    "\n",
    "![title](img/folder.jpg)\n",
    "\n",
    "It has several folders with redundant files in different formats, mainly .sph and .stm\n",
    "\n",
    "It also comes with the files separated in train and test. The train folder has 2351 files and test 11. We'll later see if this is an apropiate distribution of the data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First transformation: SPH to WAV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPH format it is not very common or used so we are going to change all the files to WAV format. WAV is one of the most common audio file format and there are many libraries and functions to work with it in Python, making this project a little easier.\n",
    "\n",
    "There are several ways for this transformation (Python functions, OS routines, specific programs, etc). We found the easiest way by running a script in the Windows CMD so the OS and SoX (Sound eXchange) will do all the work. This is the script:\n",
    "\n",
    "![title](img/script.jpg)\n",
    "\n",
    "Once the script has finished, we have all the files in WAV format, ready to be read by this Notebook :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions, getting and preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the files and work with them we are going to need the following imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T09:07:33.397476Z",
     "start_time": "2019-05-30T09:07:30.870560Z"
    }
   },
   "outputs": [],
   "source": [
    "# (Double check if I need all these)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# To play WAVs on this Notebook\n",
    "import IPython.display as ipd\n",
    "\n",
    "# For random noise\n",
    "import random\n",
    "\n",
    "# To save with the current data and time\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "%matplotlib inline\n",
    "\n",
    "# Try this to disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# To see times\n",
    "from tqdm import tqdm_notebook, tnrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to memory limitations, files are going to be load in two different steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets locate and open all the WAVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.066276Z",
     "start_time": "2019-05-20T08:15:01.062287Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def w_files():    \n",
    "    \n",
    "    # Load all the wavs (names) into a list\n",
    "\n",
    "    path1 = 'D:/Datasets/Ted Talks TEDLIUM/TEDLIUM_release-3/FINAL/load1/'\n",
    "    path2 = 'D:/Datasets/Ted Talks TEDLIUM/TEDLIUM_release-3/FINAL/load2/'\n",
    "\n",
    "    WAV_list1 = os.listdir(path1)\n",
    "    WAV_list2 = os.listdir(path2)\n",
    "\n",
    "    WAV_list1 = pd.DataFrame(WAV_list1)\n",
    "    WAV_list2 = pd.DataFrame(WAV_list2)\n",
    "\n",
    "    print('First, ', len(WAV_list1), 'files are going to be load and this are the names:')\n",
    "    display(WAV_list1)\n",
    "\n",
    "    print('Then, ', len(WAV_list2), 'files are going to be load and this are the names:')\n",
    "    display(WAV_list2)\n",
    "    \n",
    "    return path1, path2, WAV_list1, WAV_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One single function for:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and loading all files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data can be read directly from the WAV files or from a CSV if this step has already been done.\n",
    "\n",
    "If you decide to load from WAVs, the files are going to be read with the function wavfile.read() and saved into a Pandas Dataframe. This option might take more than 30 min.\n",
    "\n",
    "If you load it from a CSV the data is load directly into the Pandas dataframe. This option takes 1 min (reading the CSV takes just a few seconds, most of the time is due to the transformation of the data that comes in a string into NumPy arrays)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to take all the data and info and we are going to load it into an empty dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.074254Z",
     "start_time": "2019-05-20T08:15:01.067274Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(WAV_list, path):    \n",
    "    \n",
    "    print('\\nReading audio files...\\n')\n",
    "\n",
    "    # Save data into another list\n",
    "    data = [0]\n",
    "\n",
    "    for i in (tnrange(len(WAV_list))):\n",
    "\n",
    "        fname = path + WAV_list.iloc[i][0]\n",
    "\n",
    "        if os.path.isfile(fname):\n",
    "            # Read file\n",
    "            Dato = wavfile.read(fname)\n",
    "            #Dato = Dato.tolist()\n",
    "            data = data + [Dato]\n",
    "\n",
    "#             if i%50 == 0:\n",
    "#                 print(len(WAV_list) - i, 'remaining')\n",
    "\n",
    "        else:\n",
    "            print(\"Something went wrong\")\n",
    "\n",
    "    data = pd.DataFrame([data])\n",
    "    data = data.T\n",
    "    data = data.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "#     if len(data) == len(WAV_list):\n",
    "#         print('\\nFinished successfully!')\n",
    "\n",
    "    WAV_list['data'] = data\n",
    "\n",
    "    # To lo tocho\n",
    "\n",
    "    # We first create the empty dataframe\n",
    "    col_names =  ['name', 'sample_rate', 'original_length', 'final_length', 'data']\n",
    "    df  = pd.DataFrame(columns = col_names)\n",
    "\n",
    "    # We create empty lists to load the data and then save it into the dataframe\n",
    "    all_data = []\n",
    "    all_rates = []\n",
    "    all_lengths = []\n",
    "\n",
    "    for i in range (len(WAV_list)):\n",
    "        all_data.append(WAV_list['data'][i][1])\n",
    "        all_rates.append(WAV_list['data'][i][0])\n",
    "        all_lengths.append(len(WAV_list['data'][i][1]))\n",
    "\n",
    "    df['name'] = WAV_list[0]\n",
    "    df['data'] = all_data\n",
    "    df['sample_rate'] = all_rates\n",
    "    df['original_length'] = all_lengths\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.082234Z",
     "start_time": "2019-05-20T08:15:01.075253Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_df(name):\n",
    "    \n",
    "    print('\\nOpening CSV...\\n')\n",
    "    df = pd.read_csv(name, index_col=[0])\n",
    "    df.index = pd.RangeIndex(len(df.index))\n",
    "    \n",
    "    print('Reading data...\\n')\n",
    "    # Esto del for es canelita en rama. cinnamon in branch.\n",
    "    for i in tnrange(df.shape[0]):\n",
    "        #df.data[i] = np.fromstring(df.data[i].replace('[', r'').replace('\\r\\n', r''), sep=' ', dtype=np.int16)\n",
    "        df.data[i] = np.fromstring(df.data[i].replace('[', r'').replace('\\r\\n', r''), sep=' ', dtype=np.float32)\n",
    "        df.random_data[i] = np.fromstring(df.random_data[i].replace('[', r'').replace('\\r\\n', r''), sep=' ', dtype=np.float32)\n",
    "        df.incompleted_data[i] = np.fromstring(df.incompleted_data[i].replace('[', r'').replace('\\r\\n', r''), sep=' ', dtype=np.float32)\n",
    "        df.low_quality_data[i] = np.fromstring(df.low_quality_data[i].replace('[', r'').replace('\\r\\n', r''), sep=' ', dtype=np.float32)\n",
    "\n",
    "    print('\\nFinished successfully!')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to prepare data to be ready and understood by a Deep Learning model.\n",
    "\n",
    "We are going to go through different steps, where we'll changing the shape, lenght, size, etc. of this data.\n",
    "\n",
    "NOTE: Most of this steps will only be effective if we load the data from the WAV files. If we already have a Dataframe that has been throght this steps, nothing will happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets see the lenghts of the original files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.090245Z",
     "start_time": "2019-05-20T08:15:01.083231Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_lenghts():\n",
    "    \n",
    "    min_len = df.original_length.min()\n",
    "    max_len = df.original_length.max()\n",
    "    avg_len = np.mean(df.original_length)\n",
    "\n",
    "    print('Max Length: ', max_len, '\\nAverage Length: ', int(avg_len), '\\nMin Length: ', min_len);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's round each value of each audio file. It has to be done after the normalization, because after it, the values result with 18 decimals.\n",
    "\n",
    "A human survey has been done to conclude how many decimals are going to be used. The survey concludes that humans cannot notice the difference between 8, 4 and 3 decimals of precision, so the number of rounding is going to be used is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.097219Z",
     "start_time": "2019-05-20T08:15:01.091210Z"
    }
   },
   "outputs": [],
   "source": [
    "def rounding(data):\n",
    "    for x in range(0, data.size):\n",
    "        data[x] = round(data[x], 3)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to chunk all the files in the same length (10 seconds).\n",
    "\n",
    "10 secs = 163333 frames.\n",
    "\n",
    "We are going to remove the first 27 seconds (Ted Intro) and take the next 10 seconds, which has actual speech.\n",
    "\n",
    "NOTE: If we want a different final length we just have to modify the values from the box below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.105172Z",
     "start_time": "2019-05-20T08:15:01.098191Z"
    }
   },
   "outputs": [],
   "source": [
    "def generic_chunk(df, beg, f_len):\n",
    "    \n",
    "    new = df[['data']].copy()\n",
    "    \n",
    "    new['data'] = [col[beg:beg+f_len] for col in tqdm_notebook(new.data)]\n",
    "    \n",
    "    # In case some file was shorten than the length we set, the remaining empty part is going be fill with 0's\n",
    "    #df['data'] = [np.pad(col, (0, f_len-len(col)), 'constant') for col in df.data if len(df.data) < f_len]\n",
    "    \n",
    "    #df['final_length'] = [len(col) for col in df.data]\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.111156Z",
     "start_time": "2019-05-20T08:15:01.106170Z"
    }
   },
   "outputs": [],
   "source": [
    "def chunk(df):\n",
    "    \n",
    "    # How much we want to cut from the beginning (441000 = 27 seconds):\n",
    "    beg = 441000\n",
    "\n",
    "    # How long we want the final length (163333 = 10 seconds)\n",
    "    f_len = 163333\n",
    "    \n",
    "    df['data'] = [col[beg:beg+f_len] for col in df.data]\n",
    "    \n",
    "    # In case some file was shorten than the length we set, the remaining empty part is going be fill with 0's\n",
    "    df['data'] = [np.pad(col, (0, f_len-len(col)), 'constant') for col in df.data if len(df.data) < f_len]\n",
    "    \n",
    "    df['final_length'] = [len(col) for col in df.data]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take the second segment for a bigger dataset.\n",
    "From second 37 to 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.119135Z",
     "start_time": "2019-05-20T08:15:01.112154Z"
    }
   },
   "outputs": [],
   "source": [
    "def chunk_2(df):\n",
    "    \n",
    "    # How much we want to cut from the beginning (604333 = 37 seconds):\n",
    "    beg = 604333\n",
    "\n",
    "    # How long we want the final length (163333 = 10 seconds)\n",
    "    f_len = 163333\n",
    "    \n",
    "    df['data'] = [col[beg:beg+f_len] for col in df.data]\n",
    "    \n",
    "    # In case some file was shorten than the length we set, the remaining empty part is going be fill with 0's\n",
    "    df['data'] = [np.pad(col, (0, f_len-len(col)), 'constant') for col in df.data if len(df.data) < f_len]\n",
    "    \n",
    "    df['final_length'] = [len(col) for col in df.data]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take the third segment for a bigger dataset.\n",
    "From second 47 to 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.126117Z",
     "start_time": "2019-05-20T08:15:01.120132Z"
    }
   },
   "outputs": [],
   "source": [
    "def chunk_3(df):\n",
    "    \n",
    "    # How much we want to cut from the beginning (604333 = 37 seconds):\n",
    "    beg = 767666\n",
    "    \n",
    "    # How long we want the final length (163333 = 10 seconds)\n",
    "    f_len = 163333\n",
    "    \n",
    "    df['data'] = [col[beg:beg+f_len] for col in df.data]\n",
    "    \n",
    "    # In case some file was shorten than the length we set, the remaining empty part is going be fill with 0's\n",
    "    df['data'] = [np.pad(col, (0, f_len-len(col)), 'constant') for col in df.data if len(df.data) < f_len]\n",
    "    \n",
    "    df['final_length'] = [len(col) for col in df.data]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking the DF to export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.133097Z",
     "start_time": "2019-05-20T08:15:01.127113Z"
    }
   },
   "outputs": [],
   "source": [
    "def preparing_df(df):\n",
    "    if 'sample_rate' in df:\n",
    "        df = df.drop(['sample_rate'], axis=1)\n",
    "        \n",
    "    if 'original_length' in df:\n",
    "        df = df.drop(['original_length'], axis=1)\n",
    "        \n",
    "    if 'final_length' in df:\n",
    "        df = df.drop(['final_length'], axis=1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (-1, 1)\n",
    "\n",
    "The one I'm gonna use\n",
    "\n",
    "Lets try one of the typical normalizations, between -1 and 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.139082Z",
     "start_time": "2019-05-20T08:15:01.134096Z"
    }
   },
   "outputs": [],
   "source": [
    "def norm_b(data):\n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    if abs(min_data) > max_data:\n",
    "        max_data = abs(min_data)\n",
    "    data = data / max_data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (0, 1)\n",
    "Check which normalization is the best workin w audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.146063Z",
     "start_time": "2019-05-20T08:15:01.140079Z"
    }
   },
   "outputs": [],
   "source": [
    "def audio_norm(data):\n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    data = (data-min_data) / (max_data - min_data+1e-6)\n",
    "    return data - 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other\n",
    "Try this other normalization from Scikit learn:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I removed it cuz it wasn't useful at all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the broken files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to prepare the broken versions of the audio files, so we have a pair of normal quality file - broken file.\n",
    "\n",
    "We want to have different kind of broken files such as low quality, noise, missing information, etc.\n",
    "\n",
    "Different methods are going to be used for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start generating one single broken version per file, and once we have done this succesfully, we'll we if its necessary to have all the different broken methods per each file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Noise\n",
    "\n",
    "This is going to be first method even though we already know that in most of the real cases the incompletion is not going to be due to this, but is a good starting point for the new broken files.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.153044Z",
     "start_time": "2019-05-20T08:15:01.147061Z"
    }
   },
   "outputs": [],
   "source": [
    "def br_random(data, p_no):\n",
    "    \n",
    "    mu = 0      # mean\n",
    "    sigma = 0.15 # standard deviation\n",
    "#     sigma = random.uniform(0.08, 0.16)\n",
    "    \n",
    "    mask = np.random.choice([0, 1], size=df.data[3].size, p=[1-p_no, p_no])\n",
    "    mask = np.array(mask, dtype=bool)\n",
    "    \n",
    "    sine = np.random.normal(mu, sigma, data.size)\n",
    "    \n",
    "    broken = data.copy()\n",
    "    broken[mask] = sine[mask]\n",
    "    \n",
    "    return broken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incomplete Noise\n",
    "\n",
    "This is the second method, it will remove some values and place 0's instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.159028Z",
     "start_time": "2019-05-20T08:15:01.154042Z"
    }
   },
   "outputs": [],
   "source": [
    "def br_incompletion(data, p_in):\n",
    "    \n",
    "    # The positions where I want to place the 0's\n",
    "    maska = np.random.choice([0, 1], size=data.size, p=[1-p_in, p_in])\n",
    "    \n",
    "    data = np.ma.array(data, mask=maska, fill_value=0)\n",
    "    resultado = data.filled()\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Quality\n",
    "\n",
    "The third method consists on reading the files with a lower sampling rate, instade of 16 kHz, 8 kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.166009Z",
     "start_time": "2019-05-20T08:15:01.160025Z"
    }
   },
   "outputs": [],
   "source": [
    "def br_low_q(data):\n",
    "    data = data[1::2]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save current work\n",
    "\n",
    "Function to save the current Pandas dataframe into a .CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to save this Dataframe into a CSV for future work.\n",
    "\n",
    "First, we have to set the threshold with a high value to make sure we don't truncate and miss data. Right after writting the CSV we'll set the threshold again with the default parameters so we can print the NumPy arrays properly.\n",
    "\n",
    "NOTE: The parameter np.set_printoptions(threshold=np.inf) should also work instead of setting the threashold with a high value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.179972Z",
     "start_time": "2019-05-20T08:15:01.173988Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_work(df, name):\n",
    "    \n",
    "    print('\\nExporting to CSV. This might take a while...\\n')\n",
    "    #np.set_printoptions(threshold=200000)\n",
    "    np.set_printoptions(threshold=164000)\n",
    "    df.to_csv(name+'.csv')\n",
    "    np.set_printoptions(edgeitems=3,infstr='inf', linewidth=75, nanstr='nan', precision=8, suppress=False, threshold=1000, formatter=None)\n",
    "    print('\\nFinished successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export group of the 4 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are going to be exported the group of the 4 files composed by: Original, random noise, incompleted and low quality.\n",
    "The starting file is a random one and it will recive how many from them will be exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.186953Z",
     "start_time": "2019-05-20T08:15:01.180970Z"
    }
   },
   "outputs": [],
   "source": [
    "def export_groups(df, num):\n",
    "    \n",
    "    if num !=0:\n",
    "        \n",
    "        r_fi =random.randint(0, len(df))\n",
    "\n",
    "        for i in tnrange(0, num):\n",
    "            wavfile.write(('outputs/Noise/'+'{}'.format(i))+'_original.wav', 16000, df['data'][i+r_fi])\n",
    "            wavfile.write(('outputs/Noise/'+'{}'.format(i))+'_random.wav', 16000, df['random_data'][i+r_fi])\n",
    "            wavfile.write(('outputs/Noise/'+'{}'.format(i))+'_incompl.wav', 16000, df['incompleted_data'][i+r_fi])\n",
    "            wavfile.write(('outputs/Noise/'+'{}'.format(i))+'_low_q.wav', 8000, df['low_quality_data'][i+r_fi])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to WAV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also export some of the files back into WAV files but with the new lengths, shapes, etc. We are going to use the wavfile.write() function.\n",
    "\n",
    "Lets export some of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.193935Z",
     "start_time": "2019-05-20T08:15:01.187951Z"
    }
   },
   "outputs": [],
   "source": [
    "def export_files():\n",
    "    \n",
    "    option = -1\n",
    "    \n",
    "    while option != 0 or option != 1 or option != 2:\n",
    "\n",
    "        print('- Enter 0 to export 10 random files')\n",
    "        print('- Enter 1 to export the first 10 files')\n",
    "        print('- Enter 2 to export one specific file')\n",
    "\n",
    "        option = input()\n",
    "        option = int(option)\n",
    "        \n",
    "        if option == 0:\n",
    "\n",
    "            for i in range(10):\n",
    "                r_fi = random.randint(0, len(df))\n",
    "                #wavfile.write(('Exported/test'+'{}'.format(r_fi))+'.wav', df['sample_rate'][r_fi], df['data'][r_fi])\n",
    "                wavfile.write(('outputs/Exported/Random_exported'+'{}'.format(i))+'_'+'{}'.format(r_fi)+'.wav', 16000, df['data'][r_fi])\n",
    "            break\n",
    "            \n",
    "        elif option == 1:\n",
    "\n",
    "            for i in range(10):\n",
    "                #wavfile.write(('Exported/test'+'{}'.format(i))+'.wav', df['sample_rate'][i], df['data'][i])\n",
    "                wavfile.write(('outputs/Exported/10first_exported'+'{}'.format(i))+'_'+'{}'.format(i)+'.wav', 16000, df['data'][i])\n",
    "            break\n",
    "            \n",
    "        elif option == 2:\n",
    "            \n",
    "            print('\\nEnter the file id you want to export:')\n",
    "            fia = input()\n",
    "            fi = int(fia)\n",
    "\n",
    "            wavfile.write(('outputs/Exported/Specific_exported'+'{}'.format(fi))+'_'+'{}'.format(fi)+'.wav', 16000, df['data'][fi])\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            print('Not a valid option, try again...\\n\\n')\n",
    "\n",
    "            \n",
    "    print('Exported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.200916Z",
     "start_time": "2019-05-20T08:15:01.194933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Frame where we start recording for the df\n",
    "beginning = 441000\n",
    "\n",
    "# Audio final length (163333 = 10sec, 81666 = 5sec, 32666 = 2sec)\n",
    "final_l = 32666 # 2 Seconds\n",
    "\n",
    "# Sample rate of all the audio files\n",
    "sample_rate = 16000\n",
    "\n",
    "# Lengths of all audios once chunked \n",
    "final_length = 163333\n",
    "\n",
    "# To chose if load from WAV's or from an existing DF\n",
    "option = -1\n",
    "\n",
    "# Percentage of noise\n",
    "p_no = 0.3\n",
    "\n",
    "# Percentage of incompletion\n",
    "p_in = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:15:01.216874Z",
     "start_time": "2019-05-20T08:15:01.201914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To check beginnins and lengths:\n",
      "First file:   441000 32666\n",
      "Second file:  473666 32666\n",
      "Third file:   506332 32666\n",
      "Fourth file:  538998 32666\n"
     ]
    }
   ],
   "source": [
    "print('To check beginnins and lengths:')\n",
    "print('First file:  ', beginning + (0*final_l), final_l)\n",
    "print('Second file: ', beginning + (1*final_l), final_l)\n",
    "print('Third file:  ', beginning + (2*final_l), final_l)\n",
    "print('Fourth file: ', beginning + (3*final_l), final_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:22:35.165477Z",
     "start_time": "2019-05-20T08:15:01.217871Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to load the data from the WAVs or from a CSV?\n",
      "Enter 0 for WAVs or 1 for CSV:\n",
      "1\n",
      "Enter the files name:\n",
      "df_all_data\n",
      "\n",
      "Opening CSV...\n",
      "\n",
      "Reading data...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398306eef3df449ea08ffef848529bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10880), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Finished successfully!\n"
     ]
    }
   ],
   "source": [
    "while option != 0 or option != 1:    \n",
    "\n",
    "    print('Do you want to load the data from the WAVs or from a CSV?')\n",
    "    print('Enter 0 for WAVs or 1 for CSV:')\n",
    "    option = input()\n",
    "    option = int(option)\n",
    "\n",
    "    if option == 0:\n",
    "        \n",
    "        path1, path2, WAV_list1, WAV_list2 = w_files()\n",
    "        \n",
    "        df1 = load_data(WAV_list1, path1)\n",
    "        time.sleep(60)\n",
    "        df2 = load_data(WAV_list2, path2)\n",
    "        \n",
    "        frames = [df1, df2]\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "        # CALL FROM HERE ALL OTHER FUNCTIONS TO PREPARE DF\n",
    "        #df = chunk(df)\n",
    "        #df = chunk_2(df)\n",
    "        #df = chunk_3(df)\n",
    "        \n",
    "        # The new chunks come here:\n",
    "        s_df0 = generic_chunk(df, beginning + (0*final_l), final_l)\n",
    "        s_df1 = generic_chunk(df, beginning + (1*final_l), final_l)\n",
    "        s_df2 = generic_chunk(df, beginning + (2*final_l), final_l)\n",
    "        s_df3 = generic_chunk(df, beginning + (3*final_l), final_l)\n",
    "        \n",
    "        frames = [s_df0, s_df1, s_df2, s_df3]\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "        df.index = pd.RangeIndex(len(df.index))\n",
    "        break\n",
    "        \n",
    "    elif option == 1:\n",
    "        \n",
    "        print('Enter the files name:')\n",
    "        name = input()\n",
    "        df = load_df('data/'+name+'.csv')\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        print('Not a valid option, try again...\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check what's load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:22:35.237877Z",
     "start_time": "2019-05-20T08:22:35.165477Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFs shape:  (10880, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>random_data</th>\n",
       "      <th>incompleted_data</th>\n",
       "      <th>low_quality_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.031, -0.024, -0.017, -0.001, -0.026, -0.03...</td>\n",
       "      <td>[-0.031, -0.277, -0.017, -0.001, -0.026, -0.03...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, -0.038, -0.043, 0.0,...</td>\n",
       "      <td>[-0.024, -0.001, -0.038, -0.062, -0.066, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.125, 0.089, 0.058, 0.027, -0.026, -0.068, -...</td>\n",
       "      <td>[0.125, 0.089, -0.132, -0.096, -0.026, -0.068,...</td>\n",
       "      <td>[0.0, 0.089, 0.0, 0.0, 0.0, -0.068, 0.0, 0.0, ...</td>\n",
       "      <td>[0.089, 0.027, -0.068, -0.113, -0.154, -0.127,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.133, 0.154, 0.16, 0.192, 0.259, 0.295, 0.23...</td>\n",
       "      <td>[-0.06, -0.091, 0.16, 0.192, -0.103, 0.295, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.295, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.154, 0.192, 0.295, 0.15, 0.052, -0.008, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.009, 0.059, 0.085, 0.061, -0.031, -0.116, ...</td>\n",
       "      <td>[-0.009, 0.316, 0.085, -0.055, -0.031, -0.116,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.061, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.059, 0.061, -0.116, -0.116, -0.004, 0.057, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.017, 0.028, 0.029, 0.027, 0.018, 0.021, 0.0...</td>\n",
       "      <td>[0.175, 0.028, 0.029, 0.027, 0.018, 0.021, -0....</td>\n",
       "      <td>[0.0, 0.028, 0.0, 0.0, 0.018, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.028, 0.027, 0.021, 0.043, 0.065, 0.05, 0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  [-0.031, -0.024, -0.017, -0.001, -0.026, -0.03...   \n",
       "1  [0.125, 0.089, 0.058, 0.027, -0.026, -0.068, -...   \n",
       "2  [0.133, 0.154, 0.16, 0.192, 0.259, 0.295, 0.23...   \n",
       "3  [-0.009, 0.059, 0.085, 0.061, -0.031, -0.116, ...   \n",
       "4  [0.017, 0.028, 0.029, 0.027, 0.018, 0.021, 0.0...   \n",
       "\n",
       "                                         random_data  \\\n",
       "0  [-0.031, -0.277, -0.017, -0.001, -0.026, -0.03...   \n",
       "1  [0.125, 0.089, -0.132, -0.096, -0.026, -0.068,...   \n",
       "2  [-0.06, -0.091, 0.16, 0.192, -0.103, 0.295, 0....   \n",
       "3  [-0.009, 0.316, 0.085, -0.055, -0.031, -0.116,...   \n",
       "4  [0.175, 0.028, 0.029, 0.027, 0.018, 0.021, -0....   \n",
       "\n",
       "                                    incompleted_data  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, -0.038, -0.043, 0.0,...   \n",
       "1  [0.0, 0.089, 0.0, 0.0, 0.0, -0.068, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.295, 0.0, 0.0, 0.0...   \n",
       "3  [0.0, 0.0, 0.0, 0.061, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  [0.0, 0.028, 0.0, 0.0, 0.018, 0.0, 0.0, 0.0, 0...   \n",
       "\n",
       "                                    low_quality_data  \n",
       "0  [-0.024, -0.001, -0.038, -0.062, -0.066, -0.09...  \n",
       "1  [0.089, 0.027, -0.068, -0.113, -0.154, -0.127,...  \n",
       "2  [0.154, 0.192, 0.295, 0.15, 0.052, -0.008, -0....  \n",
       "3  [0.059, 0.061, -0.116, -0.116, -0.004, 0.057, ...  \n",
       "4  [0.028, 0.027, 0.021, 0.043, 0.065, 0.05, 0.03...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('DFs shape: ', df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:27:08.173338Z",
     "start_time": "2019-05-20T08:22:35.239889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you are building a new Dataset, enter 0\n",
      "If you are checking an existing CSV or modifying rates, enter 1\n",
      "1\n",
      "\n",
      "The current dataset is:\n",
      "DFs shape:  (10880, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>random_data</th>\n",
       "      <th>incompleted_data</th>\n",
       "      <th>low_quality_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.031, -0.024, -0.017, -0.001, -0.026, -0.03...</td>\n",
       "      <td>[-0.031, -0.277, -0.017, -0.001, -0.026, -0.03...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, -0.038, -0.043, 0.0,...</td>\n",
       "      <td>[-0.024, -0.001, -0.038, -0.062, -0.066, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.125, 0.089, 0.058, 0.027, -0.026, -0.068, -...</td>\n",
       "      <td>[0.125, 0.089, -0.132, -0.096, -0.026, -0.068,...</td>\n",
       "      <td>[0.0, 0.089, 0.0, 0.0, 0.0, -0.068, 0.0, 0.0, ...</td>\n",
       "      <td>[0.089, 0.027, -0.068, -0.113, -0.154, -0.127,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.133, 0.154, 0.16, 0.192, 0.259, 0.295, 0.23...</td>\n",
       "      <td>[-0.06, -0.091, 0.16, 0.192, -0.103, 0.295, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.295, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.154, 0.192, 0.295, 0.15, 0.052, -0.008, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.009, 0.059, 0.085, 0.061, -0.031, -0.116, ...</td>\n",
       "      <td>[-0.009, 0.316, 0.085, -0.055, -0.031, -0.116,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.061, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.059, 0.061, -0.116, -0.116, -0.004, 0.057, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.017, 0.028, 0.029, 0.027, 0.018, 0.021, 0.0...</td>\n",
       "      <td>[0.175, 0.028, 0.029, 0.027, 0.018, 0.021, -0....</td>\n",
       "      <td>[0.0, 0.028, 0.0, 0.0, 0.018, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.028, 0.027, 0.021, 0.043, 0.065, 0.05, 0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  [-0.031, -0.024, -0.017, -0.001, -0.026, -0.03...   \n",
       "1  [0.125, 0.089, 0.058, 0.027, -0.026, -0.068, -...   \n",
       "2  [0.133, 0.154, 0.16, 0.192, 0.259, 0.295, 0.23...   \n",
       "3  [-0.009, 0.059, 0.085, 0.061, -0.031, -0.116, ...   \n",
       "4  [0.017, 0.028, 0.029, 0.027, 0.018, 0.021, 0.0...   \n",
       "\n",
       "                                         random_data  \\\n",
       "0  [-0.031, -0.277, -0.017, -0.001, -0.026, -0.03...   \n",
       "1  [0.125, 0.089, -0.132, -0.096, -0.026, -0.068,...   \n",
       "2  [-0.06, -0.091, 0.16, 0.192, -0.103, 0.295, 0....   \n",
       "3  [-0.009, 0.316, 0.085, -0.055, -0.031, -0.116,...   \n",
       "4  [0.175, 0.028, 0.029, 0.027, 0.018, 0.021, -0....   \n",
       "\n",
       "                                    incompleted_data  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, -0.038, -0.043, 0.0,...   \n",
       "1  [0.0, 0.089, 0.0, 0.0, 0.0, -0.068, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.295, 0.0, 0.0, 0.0...   \n",
       "3  [0.0, 0.0, 0.0, 0.061, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  [0.0, 0.028, 0.0, 0.0, 0.018, 0.0, 0.0, 0.0, 0...   \n",
       "\n",
       "                                    low_quality_data  \n",
       "0  [-0.024, -0.001, -0.038, -0.062, -0.066, -0.09...  \n",
       "1  [0.089, 0.027, -0.068, -0.113, -0.154, -0.127,...  \n",
       "2  [0.154, 0.192, 0.295, 0.15, 0.052, -0.008, -0....  \n",
       "3  [0.059, 0.061, -0.116, -0.116, -0.004, 0.057, ...  \n",
       "4  [0.028, 0.027, 0.021, 0.043, 0.065, 0.05, 0.03...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('If you are building a new Dataset, enter 0')\n",
    "print('If you are checking an existing CSV or modifying rates, enter 1')\n",
    "mods = input()\n",
    "mods = int(mods)\n",
    "\n",
    "if mods == 0:\n",
    "    print('Nice, keep it goin')\n",
    "\n",
    "elif mods == 1:\n",
    "    print('\\nThe current dataset is:')\n",
    "    print('DFs shape: ', df.shape)\n",
    "    display(df.head())\n",
    "\n",
    "else:\n",
    "    print('Wrong option')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets chunk all files in half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:27:08.188270Z",
     "start_time": "2019-05-20T08:27:08.178324Z"
    }
   },
   "outputs": [],
   "source": [
    "if mods == 0:\n",
    "    for i in range(len(df)):\n",
    "        df.data[i] = df.data[i][:final_l]\n",
    "\n",
    "    print(df.data[0].size, df.data[10].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:27:08.215198Z",
     "start_time": "2019-05-20T08:27:08.204228Z"
    }
   },
   "outputs": [],
   "source": [
    "if mods == 0:\n",
    "    for i in tnrange(len(df)):\n",
    "        df.data[i] = norm_b(df.data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:27:08.242125Z",
     "start_time": "2019-05-20T08:27:08.231155Z"
    }
   },
   "outputs": [],
   "source": [
    "if mods == 0:\n",
    "    for i in tnrange(len(df)):\n",
    "        df.data[i] = rounding(df.data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets export some files to check everything has loades and normalized properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:27:08.275038Z",
     "start_time": "2019-05-20T08:27:08.266062Z"
    }
   },
   "outputs": [],
   "source": [
    "if mods == 0:\n",
    "    export_files()\n",
    "    print('Original files exported in outputs/Exported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:27:08.436606Z",
     "start_time": "2019-05-20T08:27:08.286009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some examples of the files:\n",
      "\n",
      "Original:\n",
      "Random noise:\n",
      "Incompleted:\n",
      "Low Quality:\n"
     ]
    }
   ],
   "source": [
    "if mods == 1:\n",
    "    \n",
    "    r_fi =random.randint(0, len(df))\n",
    "\n",
    "    print('Here are some examples of the files:\\n')\n",
    "    print('Original:')\n",
    "    ipd.Audio(df.data[r_fi], rate=16000)\n",
    "    print('Random noise:')\n",
    "    ipd.Audio(df.random_data[r_fi], rate=16000)\n",
    "    print('Incompleted:')\n",
    "    ipd.Audio(df.incompleted_data[r_fi], rate=16000)\n",
    "    print('Low Quality:')\n",
    "    ipd.Audio(df.low_quality_data[r_fi], rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:28:25.038056Z",
     "start_time": "2019-05-20T08:27:08.441593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to modify the noise and broken rates?\n",
      "The current values are:\n",
      "Percentage of noise: 0.3\n",
      "Percentage of incompletion: 0.7\n",
      "\n",
      "Enter 0 for NO or 1 for YES\n",
      "0\n",
      "\n",
      "The current dataset is:\n",
      "DFs shape:  (10880, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>random_data</th>\n",
       "      <th>incompleted_data</th>\n",
       "      <th>low_quality_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.031, -0.024, -0.017, -0.001, -0.026, -0.03...</td>\n",
       "      <td>[-0.031, -0.277, -0.017, -0.001, -0.026, -0.03...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, -0.038, -0.043, 0.0,...</td>\n",
       "      <td>[-0.024, -0.001, -0.038, -0.062, -0.066, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.125, 0.089, 0.058, 0.027, -0.026, -0.068, -...</td>\n",
       "      <td>[0.125, 0.089, -0.132, -0.096, -0.026, -0.068,...</td>\n",
       "      <td>[0.0, 0.089, 0.0, 0.0, 0.0, -0.068, 0.0, 0.0, ...</td>\n",
       "      <td>[0.089, 0.027, -0.068, -0.113, -0.154, -0.127,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.133, 0.154, 0.16, 0.192, 0.259, 0.295, 0.23...</td>\n",
       "      <td>[-0.06, -0.091, 0.16, 0.192, -0.103, 0.295, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.295, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.154, 0.192, 0.295, 0.15, 0.052, -0.008, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.009, 0.059, 0.085, 0.061, -0.031, -0.116, ...</td>\n",
       "      <td>[-0.009, 0.316, 0.085, -0.055, -0.031, -0.116,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.061, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.059, 0.061, -0.116, -0.116, -0.004, 0.057, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.017, 0.028, 0.029, 0.027, 0.018, 0.021, 0.0...</td>\n",
       "      <td>[0.175, 0.028, 0.029, 0.027, 0.018, 0.021, -0....</td>\n",
       "      <td>[0.0, 0.028, 0.0, 0.0, 0.018, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.028, 0.027, 0.021, 0.043, 0.065, 0.05, 0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  [-0.031, -0.024, -0.017, -0.001, -0.026, -0.03...   \n",
       "1  [0.125, 0.089, 0.058, 0.027, -0.026, -0.068, -...   \n",
       "2  [0.133, 0.154, 0.16, 0.192, 0.259, 0.295, 0.23...   \n",
       "3  [-0.009, 0.059, 0.085, 0.061, -0.031, -0.116, ...   \n",
       "4  [0.017, 0.028, 0.029, 0.027, 0.018, 0.021, 0.0...   \n",
       "\n",
       "                                         random_data  \\\n",
       "0  [-0.031, -0.277, -0.017, -0.001, -0.026, -0.03...   \n",
       "1  [0.125, 0.089, -0.132, -0.096, -0.026, -0.068,...   \n",
       "2  [-0.06, -0.091, 0.16, 0.192, -0.103, 0.295, 0....   \n",
       "3  [-0.009, 0.316, 0.085, -0.055, -0.031, -0.116,...   \n",
       "4  [0.175, 0.028, 0.029, 0.027, 0.018, 0.021, -0....   \n",
       "\n",
       "                                    incompleted_data  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, -0.038, -0.043, 0.0,...   \n",
       "1  [0.0, 0.089, 0.0, 0.0, 0.0, -0.068, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.295, 0.0, 0.0, 0.0...   \n",
       "3  [0.0, 0.0, 0.0, 0.061, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  [0.0, 0.028, 0.0, 0.0, 0.018, 0.0, 0.0, 0.0, 0...   \n",
       "\n",
       "                                    low_quality_data  \n",
       "0  [-0.024, -0.001, -0.038, -0.062, -0.066, -0.09...  \n",
       "1  [0.089, 0.027, -0.068, -0.113, -0.154, -0.127,...  \n",
       "2  [0.154, 0.192, 0.295, 0.15, 0.052, -0.008, -0....  \n",
       "3  [0.059, 0.061, -0.116, -0.116, -0.004, 0.057, ...  \n",
       "4  [0.028, 0.027, 0.021, 0.043, 0.065, 0.05, 0.03...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if mods == 1:\n",
    "    print('Do you want to modify the noise and broken rates?')\n",
    "    print('The current values are:')\n",
    "    print('Percentage of noise:', p_no)\n",
    "    print('Percentage of incompletion:', p_in)\n",
    "    print('\\nEnter 0 for NO or 1 for YES')\n",
    "    change = input()\n",
    "    change = int(change)\n",
    "\n",
    "    if change == 0:\n",
    "        print('\\nThe current dataset is:')\n",
    "        print('DFs shape: ', df.shape)\n",
    "        display(df.head())\n",
    "\n",
    "    elif change == 1:\n",
    "        print('Enter the new Percentage of noise:')\n",
    "        new_p_no = input()\n",
    "        p_no = float(new_p_no)\n",
    "        print('\\nEnter the new Percentage of incompletion:')\n",
    "        new_p_in = input()\n",
    "        p_in = float(new_p_in)\n",
    "        print('\\nValues changed successfully!')\n",
    "\n",
    "    else:\n",
    "        print('Wrong option')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:28:25.059997Z",
     "start_time": "2019-05-20T08:28:25.049054Z"
    }
   },
   "outputs": [],
   "source": [
    "if (mods == 0 ) or (mods == 1 and change == 1):\n",
    "    print('Aqui es cuando debería rehacer las roturas, sino no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:28:25.077949Z",
     "start_time": "2019-05-20T08:28:25.066978Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if (mods == 0) or (mods == 1 and change == 1):\n",
    "    \n",
    "    if 'random_data' in df:\n",
    "        df = df.drop(['random_data'], axis=1)\n",
    "\n",
    "    broken_r = []\n",
    "\n",
    "    for i in tnrange(len(df)):\n",
    "        broken_r.append(br_random(df.data[i], p_no))\n",
    "\n",
    "    df['random_data'] = broken_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the incompleted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:28:25.092909Z",
     "start_time": "2019-05-20T08:28:25.082936Z"
    }
   },
   "outputs": [],
   "source": [
    "if (mods == 0) or (mods == 1 and change == 1):\n",
    "\n",
    "    if 'incompleted_data' in df:\n",
    "        df = df.drop(['incompleted_data'], axis=1)\n",
    "\n",
    "    broken_i = []\n",
    "\n",
    "    for i in tnrange(len(df)):\n",
    "        broken_i.append(br_incompletion(df.data[i], p_in))\n",
    "\n",
    "    df['incompleted_data'] = broken_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the low quality files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:28:25.117842Z",
     "start_time": "2019-05-20T08:28:25.106872Z"
    }
   },
   "outputs": [],
   "source": [
    "if (mods == 0) or (mods == 1 and change == 1):\n",
    "\n",
    "    if 'low_quality_data' in df:\n",
    "        df = df.drop(['low_quality_data'], axis=1)\n",
    "\n",
    "    broken_l = []\n",
    "\n",
    "    for i in tnrange(len(df)):\n",
    "        broken_l.append(br_low_q(df.data[i]))\n",
    "\n",
    "    df['low_quality_data'] = broken_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have to round again the new data just created, all the broken files that might also have more than 3 decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:28:25.143773Z",
     "start_time": "2019-05-20T08:28:25.136792Z"
    }
   },
   "outputs": [],
   "source": [
    "if (mods == 0) or (mods == 1 and change == 1):\n",
    "\n",
    "    for i in tnrange(len(df)):\n",
    "        df.random_data[i] = rounding(df.random_data[i])\n",
    "        df.incompleted_data[i] = rounding(df.incompleted_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets export some of this files with its 3 versions to see how it sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:28:35.958883Z",
     "start_time": "2019-05-20T08:28:25.153747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to export some final files in WAV format?\n",
      "\n",
      "Enter how many different files you want to listen. 0 for none.\n",
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba0a0826d8e48f1a9bf7717f975a627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files exported in: outputs/Noise\n"
     ]
    }
   ],
   "source": [
    "print('Do you want to export some final files in WAV format?')\n",
    "print('\\nEnter how many different files you want to listen. 0 for none.')\n",
    "exports = input()\n",
    "exports = int(exports)\n",
    "\n",
    "export_groups(df, exports)\n",
    "\n",
    "print('Files exported in: outputs/Noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare DF to be exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:28:36.008750Z",
     "start_time": "2019-05-20T08:28:35.964891Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFs shape:  (10880, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>random_data</th>\n",
       "      <th>incompleted_data</th>\n",
       "      <th>low_quality_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.031, -0.024, -0.017, -0.001, -0.026, -0.03...</td>\n",
       "      <td>[-0.031, -0.277, -0.017, -0.001, -0.026, -0.03...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, -0.038, -0.043, 0.0,...</td>\n",
       "      <td>[-0.024, -0.001, -0.038, -0.062, -0.066, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.125, 0.089, 0.058, 0.027, -0.026, -0.068, -...</td>\n",
       "      <td>[0.125, 0.089, -0.132, -0.096, -0.026, -0.068,...</td>\n",
       "      <td>[0.0, 0.089, 0.0, 0.0, 0.0, -0.068, 0.0, 0.0, ...</td>\n",
       "      <td>[0.089, 0.027, -0.068, -0.113, -0.154, -0.127,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.133, 0.154, 0.16, 0.192, 0.259, 0.295, 0.23...</td>\n",
       "      <td>[-0.06, -0.091, 0.16, 0.192, -0.103, 0.295, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.295, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.154, 0.192, 0.295, 0.15, 0.052, -0.008, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.009, 0.059, 0.085, 0.061, -0.031, -0.116, ...</td>\n",
       "      <td>[-0.009, 0.316, 0.085, -0.055, -0.031, -0.116,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.061, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.059, 0.061, -0.116, -0.116, -0.004, 0.057, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.017, 0.028, 0.029, 0.027, 0.018, 0.021, 0.0...</td>\n",
       "      <td>[0.175, 0.028, 0.029, 0.027, 0.018, 0.021, -0....</td>\n",
       "      <td>[0.0, 0.028, 0.0, 0.0, 0.018, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.028, 0.027, 0.021, 0.043, 0.065, 0.05, 0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  [-0.031, -0.024, -0.017, -0.001, -0.026, -0.03...   \n",
       "1  [0.125, 0.089, 0.058, 0.027, -0.026, -0.068, -...   \n",
       "2  [0.133, 0.154, 0.16, 0.192, 0.259, 0.295, 0.23...   \n",
       "3  [-0.009, 0.059, 0.085, 0.061, -0.031, -0.116, ...   \n",
       "4  [0.017, 0.028, 0.029, 0.027, 0.018, 0.021, 0.0...   \n",
       "\n",
       "                                         random_data  \\\n",
       "0  [-0.031, -0.277, -0.017, -0.001, -0.026, -0.03...   \n",
       "1  [0.125, 0.089, -0.132, -0.096, -0.026, -0.068,...   \n",
       "2  [-0.06, -0.091, 0.16, 0.192, -0.103, 0.295, 0....   \n",
       "3  [-0.009, 0.316, 0.085, -0.055, -0.031, -0.116,...   \n",
       "4  [0.175, 0.028, 0.029, 0.027, 0.018, 0.021, -0....   \n",
       "\n",
       "                                    incompleted_data  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, -0.038, -0.043, 0.0,...   \n",
       "1  [0.0, 0.089, 0.0, 0.0, 0.0, -0.068, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.295, 0.0, 0.0, 0.0...   \n",
       "3  [0.0, 0.0, 0.0, 0.061, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  [0.0, 0.028, 0.0, 0.0, 0.018, 0.0, 0.0, 0.0, 0...   \n",
       "\n",
       "                                    low_quality_data  \n",
       "0  [-0.024, -0.001, -0.038, -0.062, -0.066, -0.09...  \n",
       "1  [0.089, 0.027, -0.068, -0.113, -0.154, -0.127,...  \n",
       "2  [0.154, 0.192, 0.295, 0.15, 0.052, -0.008, -0....  \n",
       "3  [0.059, 0.061, -0.116, -0.116, -0.004, 0.057, ...  \n",
       "4  [0.028, 0.027, 0.021, 0.043, 0.065, 0.05, 0.03...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just in case...\n",
    "df = preparing_df(df)\n",
    "\n",
    "print('DFs shape: ', df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save into a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:28:39.178972Z",
     "start_time": "2019-05-20T08:28:36.013737Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to save the DF into a CSV?\n",
      "Enter 0 to exit or 1 to save\n",
      "0\n",
      "\n",
      "This is the final DF\n",
      "DFs shape:  (10880, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>random_data</th>\n",
       "      <th>incompleted_data</th>\n",
       "      <th>low_quality_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.031, -0.024, -0.017, -0.001, -0.026, -0.03...</td>\n",
       "      <td>[-0.031, -0.277, -0.017, -0.001, -0.026, -0.03...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, -0.038, -0.043, 0.0,...</td>\n",
       "      <td>[-0.024, -0.001, -0.038, -0.062, -0.066, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.125, 0.089, 0.058, 0.027, -0.026, -0.068, -...</td>\n",
       "      <td>[0.125, 0.089, -0.132, -0.096, -0.026, -0.068,...</td>\n",
       "      <td>[0.0, 0.089, 0.0, 0.0, 0.0, -0.068, 0.0, 0.0, ...</td>\n",
       "      <td>[0.089, 0.027, -0.068, -0.113, -0.154, -0.127,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.133, 0.154, 0.16, 0.192, 0.259, 0.295, 0.23...</td>\n",
       "      <td>[-0.06, -0.091, 0.16, 0.192, -0.103, 0.295, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.295, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.154, 0.192, 0.295, 0.15, 0.052, -0.008, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.009, 0.059, 0.085, 0.061, -0.031, -0.116, ...</td>\n",
       "      <td>[-0.009, 0.316, 0.085, -0.055, -0.031, -0.116,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.061, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.059, 0.061, -0.116, -0.116, -0.004, 0.057, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.017, 0.028, 0.029, 0.027, 0.018, 0.021, 0.0...</td>\n",
       "      <td>[0.175, 0.028, 0.029, 0.027, 0.018, 0.021, -0....</td>\n",
       "      <td>[0.0, 0.028, 0.0, 0.0, 0.018, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.028, 0.027, 0.021, 0.043, 0.065, 0.05, 0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  [-0.031, -0.024, -0.017, -0.001, -0.026, -0.03...   \n",
       "1  [0.125, 0.089, 0.058, 0.027, -0.026, -0.068, -...   \n",
       "2  [0.133, 0.154, 0.16, 0.192, 0.259, 0.295, 0.23...   \n",
       "3  [-0.009, 0.059, 0.085, 0.061, -0.031, -0.116, ...   \n",
       "4  [0.017, 0.028, 0.029, 0.027, 0.018, 0.021, 0.0...   \n",
       "\n",
       "                                         random_data  \\\n",
       "0  [-0.031, -0.277, -0.017, -0.001, -0.026, -0.03...   \n",
       "1  [0.125, 0.089, -0.132, -0.096, -0.026, -0.068,...   \n",
       "2  [-0.06, -0.091, 0.16, 0.192, -0.103, 0.295, 0....   \n",
       "3  [-0.009, 0.316, 0.085, -0.055, -0.031, -0.116,...   \n",
       "4  [0.175, 0.028, 0.029, 0.027, 0.018, 0.021, -0....   \n",
       "\n",
       "                                    incompleted_data  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, -0.038, -0.043, 0.0,...   \n",
       "1  [0.0, 0.089, 0.0, 0.0, 0.0, -0.068, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.295, 0.0, 0.0, 0.0...   \n",
       "3  [0.0, 0.0, 0.0, 0.061, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  [0.0, 0.028, 0.0, 0.0, 0.018, 0.0, 0.0, 0.0, 0...   \n",
       "\n",
       "                                    low_quality_data  \n",
       "0  [-0.024, -0.001, -0.038, -0.062, -0.066, -0.09...  \n",
       "1  [0.089, 0.027, -0.068, -0.113, -0.154, -0.127,...  \n",
       "2  [0.154, 0.192, 0.295, 0.15, 0.052, -0.008, -0....  \n",
       "3  [0.059, 0.061, -0.116, -0.116, -0.004, 0.057, ...  \n",
       "4  [0.028, 0.027, 0.021, 0.043, 0.065, 0.05, 0.03...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Do you want to save the DF into a CSV?')\n",
    "print('Enter 0 to exit or 1 to save')\n",
    "saave = input()\n",
    "saave = int(saave)\n",
    "\n",
    "if saave == 0:\n",
    "    print('\\nThis is the final DF')\n",
    "    print('DFs shape: ', df.shape)\n",
    "    display(df.head())\n",
    "\n",
    "elif saave == 1:\n",
    "    \n",
    "    print('Enter the name for the CVS')\n",
    "    print('Warning: if you enter an existing name, you will lose that CSV')\n",
    "    name = input()\n",
    "    save_work(df, 'name')\n",
    "\n",
    "else:\n",
    "    print('Wrong option')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Santiago Donaher @ CEIEC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "322px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 792.4008180000001,
   "position": {
    "height": "40px",
    "left": "1525.3px",
    "right": "20px",
    "top": "113.844px",
    "width": "366.594px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
